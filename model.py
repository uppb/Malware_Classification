import tensorflow as tf
import settings

from tensorflow.keras import layers
from tensorflow.keras import losses

#Set Parameters
parameters = settings.get_parameters()
path = parameters["project_path"]
train_dataset_dir = parameters["train_save_path"]
val_dataset_dir = parameters["val_save_path"]
checkpoint_path = parameters["checkpoint_path"]
log_dir = parameters["log_path"]

batch_size = settings.batch_size
epochs = settings.epochs


#Get dataset
train_ds = tf.data.experimental.load(train_dataset_dir)
val_ds = tf.data.experimental.load(val_dataset_dir)

#Get Input_Size
input_shape = tf.shape(train_ds.take(1).get_single_element()[0])[1:]

#THE model
test_model = tf.keras.models.Sequential([
    layers.Masking(tf.constant(0,dtype=tf.float32),input_shape=input_shape),
    layers.Conv1D(16, 128, padding="valid", activation="relu"),
    layers.MaxPool1D(16),
    layers.Conv1D(32, 128, padding="valid", activation="relu"),
    layers.MaxPool1D(16),
    layers.Conv1D(64, 128, padding="valid", activation="relu"),
    layers.Dropout(0.5),
    # layers.GRU(256),
    layers.GlobalMaxPool1D(),
    layers.Dense(64, activation="relu"),
    layers.Dense(9),
])
test_model.compile(
    loss=losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer="adam",
    metrics=["accuracy"]
)


#Save Model Weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
#Log training data to tensorboard
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

#Early stop callbacks/ stop training if
es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)

#Train Model
callback_list = [cp_callback,tensorboard_callback,es_callback]
test_model.summary()
test_model.fit(train_ds,validation_data=val_ds,epochs=epochs,callbacks=callback_list)
