import tensorflow as tf


from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras.models import Model

def convBlock(input,layer_num,filters,kernel_size,strides=1,pool_size=0):
    output = input
    for i in range(layer_num):
        output = layers.Conv1D(filters,kernel_size,strides=strides,padding="valid",activation="relu")(output)
    if(pool_size > 1):
        output = layers.MaxPool1D(pool_size)(output)
    return output


def cnn(input_shape):
    inputs = layers.Input(input_shape)
    x = layers.Masking(tf.constant(0,dtype=tf.float32))(inputs)
    x = convBlock(x,layers=2,filters=16,kernel_size=64,strides=2,pool_size=16)
    #x = convBlock(x,32,64,2,8)
    #x = convBlock(x,64,32,2,4)

    x = layers.GlobalMaxPooling1D() (x)
    x = layers.Dense(64, activation="relu") (x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(9) (x)

    model = Model(inputs=inputs, outputs=outputs)

    model.compile(
        loss=losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer="adam",
        metrics=["accuracy"]
    )

    return model

def cnn_attention(input_shape):
    inputs = layers.Input(input_shape)
    x = layers.Masking(tf.constant(0,dtype=tf.float32))(inputs)
    #CONV
    conv1 = convBlock(x,layer_num=2,filters=128,kernel_size=64,strides=2,pool_size=8)
    conv2 = convBlock(conv1,layer_num=2,filters=128,kernel_size=32,strides=2,pool_size=0)

    fc1 = layers.Dense(128, activation="selu") (conv2)
    #ATTENTION
    attention1 = layers.Attention(use_scale=True)([conv1, fc1])
    attention2 = layers.Attention(use_scale=True)([conv2, fc1])
    attention1 = layers.GlobalAveragePooling1D()(attention1)
    attention2 = layers.GlobalAveragePooling1D()(attention2)
    x = layers.Concatenate(axis=1)([attention1,attention2])
    #DENSE
    x = layers.Dense(128, activation="selu") (x)
    x = layers.Dropout(0.25)(x)
    outputs = layers.Dense(9) (x)

    model = Model(inputs=inputs, outputs=outputs)

    model.compile(
        loss=losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer="adam",
        metrics=["accuracy"]
    )

    return model