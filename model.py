import tensorflow as tf
import pathlib
import numpy as np

from tensorflow.keras import layers
from tensorflow.keras import losses

#Set Parameters
path = str(pathlib.Path.home()) + "/School/Comps/"
train_dir = str(pathlib.Path.home()) + "/School/Comps/dataset/train/"
train_dataset_dir = path + "dataset/train_save"
val_dataset_dir = path + "/dataset/val_save"
model_dir = path + "models/model"
checkpoint_path = path + "training_1/cp.ckpt"

batch_size = 32
epochs = 25


#Get dataset
train_ds = tf.data.experimental.load(train_dataset_dir)
val_ds = tf.data.experimental.load(val_dataset_dir)

#Get Input_Size
input_shape = tf.shape(train_ds.take(1).get_single_element()[0])[1:]

#THE model
test_model = tf.keras.models.Sequential([
    layers.Input(input_shape,batch_size=batch_size),
    #layers.Embedding(256,32,mask_zero=True,trainable=True),
    layers.Conv1D(16,4,padding="valid",activation="relu",strides=2),
    layers.Flatten(),
    layers.Dense(900,activation="relu"),
    layers.Dense(9),
])
test_model.compile(
    loss=losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer="adam",
    metrics=["accuracy"]
)


#Save Model Weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
#Train Model
test_model.summary()
test_model.fit(train_ds,epochs=epochs,callbacks=[cp_callback])

#test = test_model.fit(train_text,train_label,batch_size=batch_size,epochs=epochs)
#test_model.save(model_dir)
